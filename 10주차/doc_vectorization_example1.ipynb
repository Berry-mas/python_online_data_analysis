{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd  \n",
    "from sklearn.feature_extraction.text import CountVectorizer # frequency based DTM (TF)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # tf-idf based DTM (IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = ['banana apple apple eggplant', \n",
    "        'orange carrot banana eggplant', \n",
    "        'apple carrot banana banana', \n",
    "        'orange banana grape'\n",
    "]  \n",
    "## 4개의 문서로 이루어진 텍스트 데이터 \n",
    "## 각각의 문서가 하나의 문자열 데이터로 저장되어있어야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer 이용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(min_df=1, max_df=0.8, ngram_range=(1,1))\n",
    "# 생성자 function\n",
    "# min_df: document frequency => 단어가 사용된 문서의 수 (문서들을 벡터로 바꿀 때 어떠한 단어들을 사용할지 결정)\n",
    "# min_df에서 지정한 숫자에 해당하는만큼 (즉 문서들 중 최소 min_df개의 이상에서 사용된 단어들만 가지고 문서들을 벡터로 바꿈)\n",
    "# min_df는 1이상의 자연수 or 0~1 소수만 입력 가능\n",
    "# min_df의 값으로 3을 입력했다면, 최소 3개의 문서에서만 사용된 단어들을 선택해서 벡터화하겠다는 것\n",
    "# min_df의 값으로 0.1을 했다면, 전체 문서들 중에서 최소 10% 이상의 문서들에서 사용된 단어들만 사용한다는 뜻\n",
    "\n",
    "# max_df: 최대 n개의 문서에서 사용된 단어들만 사용 \n",
    "# max_df도 마찬가지로 1이상의 자연수 or 0~1 소수 입력 가능\n",
    "# max_df=10 -> 최대 10개의 문서에서만 사용된 단어들을 사용 (너무 많이 사용되는 단어, 예를 들어 불용어를 제거하기 위함)\n",
    "# max_Df=0.9 -> 최대 90%. 90% 넘는 문서들에서 사용된 단어들은 벡터화하지 않겠다는 것\n",
    "\n",
    "# ngrm_range (사용하고자 하는 ngram의 범위) -> 보통 unigram만 사용\n",
    "# ngram은 연속된 n개의 단어: n개의 연속된 단어만 하나의 텀으로 사용해서 각각을 벡터로 바꾸는 것\n",
    "# ngram_range=(1,2) -> bi-gram(두 개의 연속된  단어를 하나의 텀으로 사용해서 각각을 벡터로 바꿈)\n",
    "# ngram_range=(1,1) -> 일반적으로 가장 많이 사용\n",
    "# ngram_range=(1,2)로 변경해 보기 -> unigram, bigram을 둘 다 사용\n",
    "\n",
    "tf_features = tf_vectorizer.fit_transform(TEXT)  ## 각각의 문서를, 지정한 단어들을 사용해서 벡터로 만들고, features에 저장\n",
    "## document term matrix에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t2\n",
      "  (0, 2)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 1)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 4)\t1\n",
      "  (3, 3)\t1\n"
     ]
    }
   ],
   "source": [
    "print(tf_features)    ## Document Term Matrix \n",
    "## (문서의 아이디, 단어의 아이디) , 빈도 정보 -> 물론 알파뱃 순서로 정렬했을 때\n",
    "## dtm이랑 형태가 달라서 보기 어려움 \n",
    "## 이를 dtm 형태로 만들고 싶으면 밑의 셀을 따라할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 1],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array(tf_features.todense())\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.449489742783178"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(features[1]-features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7320508075688772"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(features[1]-features[2])   ## 거리가 짧은 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['apple', 'carrot', 'eggplant', 'grape', 'orange'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = tf_vectorizer.get_feature_names_out()\n",
    "feature_names   ##위에 있는 dtm의 열 순서를 알 수 있음 (각각의 문서를 벡터화할 때 사용된 단어 정보)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   apple  carrot  eggplant  grape  orange\n",
      "0      2       0         1      0       0\n",
      "1      0       1         1      0       1\n",
      "2      1       1         0      0       0\n",
      "3      0       0         0      1       1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame(data=features, columns=feature_names)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizer 이용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df=1, ngram_range=(1,1))\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(TEXT) ## tfidvectorizer을 이용하여 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.85764287, 0.28383251, 0.        , 0.42882143, 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.35696573, 0.53931298, 0.53931298, 0.        ,\n",
       "         0.53931298],\n",
       "        [0.51623315, 0.68337886, 0.51623315, 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.37919167, 0.        , 0.        , 0.72664149,\n",
       "         0.5728925 ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_features.todense()\n",
    "## tfidf_feature을 행렬로 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85764287, 0.28383251, 0.        , 0.42882143, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.35696573, 0.53931298, 0.53931298, 0.        ,\n",
       "        0.53931298],\n",
       "       [0.51623315, 0.68337886, 0.51623315, 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.37919167, 0.        , 0.        , 0.72664149,\n",
       "        0.5728925 ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_features = np.array(tfidf_features.todense())\n",
    "tfidf_features\n",
    "## tfidf_features.todense()를 어레이로 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85764287, 0.28383251, 0.        , 0.42882143, 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
