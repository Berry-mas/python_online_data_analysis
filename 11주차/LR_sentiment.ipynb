{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Korean_movie_reviews_2016_small.txt', encoding='utf-8') as f:\n",
    "    docs = [doc.strip().split('\\t') for doc in f]\n",
    "    docs = [(doc[0], int(doc[1])) for doc in docs if len(doc) == 2]\n",
    "    texts, labels = zip(*docs) # 둘을 분리해서 별도의 list 변수로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11994\n",
      "22909\n"
     ]
    }
   ],
   "source": [
    "print(sum(labels))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CounterVectorizer 클래스를 이용한 벡터 표현\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "tf_vectorizer = CountVectorizer()\n",
    "tf_train_features = tf_vectorizer.fit_transform(train_texts) \n",
    "tf_test_features = tf_vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tf_l1 = LogisticRegression(C=0.5, penalty='l1', solver='saga', max_iter=10000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.5, max_iter=10000, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.5, max_iter=10000, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.5, max_iter=10000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_tf_l1.fit(tf_train_features, train_labels) # 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels_tf_l1 = lr_tf_l1.predict(tf_test_features) # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 871,  233],\n",
       "       [ 126, 1061]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_labels, pred_labels_tf_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83      1104\n",
      "           1       0.82      0.89      0.86      1187\n",
      "\n",
      "    accuracy                           0.84      2291\n",
      "   macro avg       0.85      0.84      0.84      2291\n",
      "weighted avg       0.85      0.84      0.84      2291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, pred_labels_tf_l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3010102 0.6989898]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# 하나의 영화평 예측하기\n",
    "print(lr_tf_l1.predict_proba(tf_test_features[0]))\n",
    "print(lr_tf_l1.predict(tf_test_features[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 긍부정 단어 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 사전 만들기\n",
    "words_dict = {}\n",
    "for word, index in tf_vectorizer.vocabulary_.items():\n",
    "    words_dict[index]=word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 단어 상위 30 개\n",
      "꿀잼 (3.447)\n",
      "감탄 (2.836)\n",
      "재밌게 (2.829)\n",
      "재밌고 (2.562)\n",
      "재미있게 (2.560)\n",
      "존잼 (2.487)\n",
      "재밌었 (2.404)\n",
      "개꿀잼 (2.367)\n",
      "여운 (2.349)\n",
      "지루하지 (2.314)\n",
      "재밌어 (2.230)\n",
      "감사합 (2.202)\n",
      "재미있었 (2.163)\n",
      "빠르 (2.159)\n",
      "흥미진진 (2.062)\n",
      "강추 (2.055)\n",
      "최고 (1.950)\n",
      "사랑해 (1.947)\n",
      "재미있어 (1.900)\n",
      "재밋어 (1.864)\n",
      "즐겁 (1.842)\n",
      "유쾌 (1.841)\n",
      "아름다운 (1.826)\n",
      "재미있네 (1.818)\n",
      "심장 (1.800)\n",
      "낮아 (1.789)\n",
      "감명 (1.755)\n",
      "재미있고 (1.749)\n",
      "재미있 (1.746)\n",
      "재밌는 (1.704)\n",
      "\n",
      "부정 단어 상위 30 개\n",
      "갑자기 (-1.961)\n",
      "지루해서 (-1.978)\n",
      "댓글알바 (-1.991)\n",
      "알바 (-2.028)\n",
      "그닥 (-2.065)\n",
      "지루하다 (-2.072)\n",
      "별로 (-2.098)\n",
      "왜곡 (-2.142)\n",
      "졸았 (-2.143)\n",
      "지루하고 (-2.147)\n",
      "전형 (-2.161)\n",
      "허무 (-2.184)\n",
      "억지 (-2.200)\n",
      "아까 (-2.234)\n",
      "신파극 (-2.257)\n",
      "짜증 (-2.308)\n",
      "아까운 (-2.352)\n",
      "재미없 (-2.366)\n",
      "엉망 (-2.405)\n",
      "망작 (-2.499)\n",
      "지루했 (-2.501)\n",
      "팔이 (-2.522)\n",
      "역사왜곡 (-2.674)\n",
      "거르 (-2.675)\n",
      "쓰레기 (-2.738)\n",
      "아까웠 (-2.803)\n",
      "이하 (-3.004)\n",
      "차라리 (-3.336)\n",
      "노잼 (-3.620)\n",
      "최악 (-4.687)\n"
     ]
    }
   ],
   "source": [
    "# Get coefficients of the model\n",
    "coefficients = lr_tf_l1.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# 학습에 사용된 각 단어마다의 coefficient (즉 weight) 값이 존재\n",
    "# coefficient값이 큰 순으로 정렬 'reverse=True'\n",
    "\n",
    "\n",
    "K=30\n",
    "# print top K positive words\n",
    "print(\"긍정 단어 상위 {} 개\".format(str(K)))\n",
    "for word_id, coef in sorted_coefficients[:K]:\n",
    "    print('{0:} ({1:.3f})'.format(words_dict[word_id], coef))\n",
    "# print top K negative words\n",
    "print(\"\\n부정 단어 상위 {} 개\".format(str(K)))\n",
    "for word_id, coef in sorted_coefficients[-K:]:\n",
    "    print('{0:} ({1:.3f})'.format(words_dict[word_id], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tf_l2 = LogisticRegression(C=0.5, penalty='l2', solver='saga', max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.5, max_iter=10000, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.5, max_iter=10000, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.5, max_iter=10000, solver='saga')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_tf_l2.fit(tf_train_features, train_labels) # 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels_tf_l2 = lr_tf_l2.predict(tf_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      1104\n",
      "           1       0.85      0.88      0.86      1187\n",
      "\n",
      "    accuracy                           0.86      2291\n",
      "   macro avg       0.86      0.86      0.86      2291\n",
      "weighted avg       0.86      0.86      0.86      2291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, pred_labels_tf_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 단어 상위 30 개\n",
      "재밌게 (2.619)\n",
      "꿀잼 (2.497)\n",
      "재미있게 (2.241)\n",
      "재밌었 (2.197)\n",
      "재밌어 (2.055)\n",
      "여운 (1.967)\n",
      "재미있었 (1.916)\n",
      "최고 (1.906)\n",
      "재밌고 (1.835)\n",
      "강추 (1.782)\n",
      "감사합 (1.722)\n",
      "지루하지 (1.704)\n",
      "감탄 (1.674)\n",
      "재미있어 (1.656)\n",
      "존잼 (1.585)\n",
      "아름다운 (1.576)\n",
      "재밌는 (1.564)\n",
      "개꿀잼 (1.529)\n",
      "재미있 (1.522)\n",
      "가는 (1.510)\n",
      "흥미진진 (1.509)\n",
      "재밋어 (1.501)\n",
      "재밌 (1.476)\n",
      "가슴 (1.466)\n",
      "지루할 (1.409)\n",
      "재미있네 (1.403)\n",
      "즐겁 (1.375)\n",
      "대박 (1.370)\n",
      "유쾌 (1.357)\n",
      "심장 (1.330)\n",
      "\n",
      "부정 단어 상위 30 개\n",
      "비추 (-1.439)\n",
      "지루하다 (-1.521)\n",
      "지루해서 (-1.541)\n",
      "아깝 (-1.583)\n",
      "지루하고 (-1.617)\n",
      "유치 (-1.618)\n",
      "그닥 (-1.641)\n",
      "엉망 (-1.645)\n",
      "졸았 (-1.654)\n",
      "자고 (-1.663)\n",
      "실망 (-1.690)\n",
      "허무 (-1.705)\n",
      "아까웠 (-1.718)\n",
      "거르 (-1.723)\n",
      "아까 (-1.744)\n",
      "팔이 (-1.770)\n",
      "망작 (-1.785)\n",
      "역사왜곡 (-1.818)\n",
      "알바 (-1.833)\n",
      "짜증 (-1.884)\n",
      "아까운 (-1.909)\n",
      "별로 (-2.026)\n",
      "지루했 (-2.028)\n",
      "억지 (-2.028)\n",
      "이하 (-2.050)\n",
      "재미없 (-2.271)\n",
      "차라리 (-2.290)\n",
      "쓰레기 (-2.395)\n",
      "노잼 (-3.173)\n",
      "최악 (-3.653)\n"
     ]
    }
   ],
   "source": [
    "# Get coefficients of the model\n",
    "coefficients = lr_tf_l2.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# 학습에 사용된 각 단어마다의 coefficient (즉 weight) 값이 존재\n",
    "# coefficient값이 큰 순으로 정렬 'reverse=True'\n",
    "\n",
    "\n",
    "K=30\n",
    "# print top K positive words\n",
    "print(\"긍정 단어 상위 {} 개\".format(str(K)))\n",
    "for word_id, coef in sorted_coefficients[:K]:\n",
    "    print('{0:} ({1:.3f})'.format(words_dict[word_id], coef))\n",
    "# print top K negative words\n",
    "print(\"\\n부정 단어 상위 {} 개\".format(str(K)))\n",
    "for word_id, coef in sorted_coefficients[-K:]:\n",
    "    print('{0:} ({1:.3f})'.format(words_dict[word_id], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
