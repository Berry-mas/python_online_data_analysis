{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer # frequency based DTM\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # tf-idf based DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def display_features(features, feature_names):\n",
    "    df = pd.DataFrame(data=features, columns=feature_names)\n",
    "    print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각각의 문서를 벡터로 바꿈\n",
    "def tf_extractor(corpus):\n",
    "    vectorizer = CountVectorizer(min_df=1, ngram_range=(1,1))\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각각의 문서를 벡터로 바꿀 때 사용 (tf_extractor와 거의 유사)\n",
    "def tfidf_extractor(corpus):\n",
    "    vectorizer = TfidfVectorizer(min_df=1, ngram_range=(1,1))\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## toy data\n",
    "TEXT = ['banana apple apple eggplant', \n",
    "        'orange carrot banana eggplant', \n",
    "        'apple carrot banana banana', \n",
    "        'orange banana grape'\n",
    "]\n",
    "## 여기 있는 문서들을 벡터로 바꿔야 한다 (빈도수 정보 or TF 정보의 IDF 정보를 반영한 정보)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer, tf_features = tf_extractor(TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer 이용하기 (단어들의 빈도수 정보)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(min_df=1, max_df=0.8, ngram_range=(1,1))\n",
    "# 생성자 function\n",
    "# min_df: document frequency => 단어가 사용된 문서의 수 (문서들을 벡터로 바꿀 때 어떠한 단어들을 사용할지 결정)\n",
    "# min_df에서 지정한 숫자에 해당하는만큼 (즉 최소 min_df개의 문서 이상에서 사용된 단어들만 가지고 문서들을 벡터로 바꿈)\n",
    "# ngrm_range\n",
    "# ngram은 연속된 n개의 단어: n개의 연속된 단어만 하나의 텀으로 사용해서 각각을 벡터로 바꾸는 것\n",
    "# ngram_range=(1,2) -> bi-gram(두 개의 연속된  단어를 하나의 텀으로 사용해서 각각을 벡터로 바꿈)\n",
    "# ngram_range=(1,1)\n",
    "# ngram_range=(1,2) 로 변경해 보기\n",
    "tf_features = tf_vectorizer.fit_transform(TEXT)  ## 각각의 문서를, 지정한 단어들을 사용해서 벡터로 만들고, features에 저장\n",
    "## document term matrix에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t2\n",
      "  (0, 2)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 1)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 4)\t1\n",
      "  (3, 3)\t1\n"
     ]
    }
   ],
   "source": [
    "print(tf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 1],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array(tf_features.todense())\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[1]  #두번째 행렬에 대한 정보\n",
    "# 각각의 단어가 해당 문서에서 얼마나 사용되었는지를 나타냄 (0번, 1번, 1번, 0번, 1번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.449489742783178"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(features[1]-features[0])\n",
    "# 두번째 문서와 첫번째 문서의 유클리디안 거리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7320508075688772"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(features[1]-features[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['apple', 'carrot', 'eggplant', 'grape', 'orange'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = tf_vectorizer.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   apple  carrot  eggplant  grape  orange\n",
      "0      2       0         1      0       0\n",
      "1      0       1         1      0       1\n",
      "2      1       1         0      0       0\n",
      "3      0       0         0      1       1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=features, columns=feature_names)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizer 이용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df=1, ngram_range=(1,1))\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85764287, 0.28383251, 0.        , 0.42882143, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.35696573, 0.53931298, 0.53931298, 0.        ,\n",
       "        0.53931298],\n",
       "       [0.51623315, 0.68337886, 0.51623315, 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.37919167, 0.        , 0.        , 0.72664149,\n",
       "        0.5728925 ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_features = np.array(tfidf_features.todense())\n",
    "tfidf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85764287, 0.28383251, 0.        , 0.42882143, 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_features[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
