{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c072c0fa-b59f-4491-b1c3-40142f9bf97b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube-comment-downloader\n",
      "  Downloading youtube_comment_downloader-0.1.76-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting dateparser (from youtube-comment-downloader)\n",
      "  Downloading dateparser-1.2.0-py2.py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from youtube-comment-downloader) (2.32.3)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from dateparser->youtube-comment-downloader) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from dateparser->youtube-comment-downloader) (2024.1)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from dateparser->youtube-comment-downloader) (2024.9.11)\n",
      "Collecting tzlocal (from dateparser->youtube-comment-downloader)\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests->youtube-comment-downloader) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests->youtube-comment-downloader) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests->youtube-comment-downloader) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests->youtube-comment-downloader) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from python-dateutil->dateparser->youtube-comment-downloader) (1.16.0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tzlocal->dateparser->youtube-comment-downloader) (2023.3)\n",
      "Downloading youtube_comment_downloader-0.1.76-py3-none-any.whl (8.2 kB)\n",
      "Downloading dateparser-1.2.0-py2.py3-none-any.whl (294 kB)\n",
      "Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: tzlocal, dateparser, youtube-comment-downloader\n",
      "Successfully installed dateparser-1.2.0 tzlocal-5.2 youtube-comment-downloader-0.1.76\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube-comment-downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d0092-b0d7-4013-b8d5-74f710cefdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 유튜브 URL 목록\n",
    "urls = [\n",
    "    'https://youtu.be/sKk_wachQoM?si=i4ZqXwZPx6VcOaZM',\n",
    "    'https://youtu.be/HC5b5Ugn0Yo?si=-lTwFmAeoAHy6AQE',\n",
    "    'https://youtu.be/SVt1-Opp3Wo?si=1My8svPXlgGIkbEM',\n",
    "]\n",
    "\n",
    "# 댓글을 저장할 CSV 파일 이름\n",
    "merged_csv_file = 'MergedYoutubeComments.csv'\n",
    "\n",
    "# 여러 URL을 순회하며 댓글을 추출\n",
    "for i, url in enumerate(urls):\n",
    "    # JSON 파일 이름\n",
    "    json_file = f'YoutubeComments_{i}.json'\n",
    "\n",
    "    # youtube-comment-downloader 명령어 실행\n",
    "    !youtube-comment-downloader --url {url} --output {json_file}\n",
    "\n",
    "    # JSON 파일 읽기\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        json_data = []\n",
    "        for line in f:\n",
    "            json_data.append(json.loads(line))\n",
    "\n",
    "    # JSON 데이터를 DataFrame으로 변환\n",
    "    df = pd.DataFrame(json_data)\n",
    "\n",
    "    # CSV 파일로 저장 (각 URL별로 저장하고 싶으면 주석 해제)\n",
    "    csv_file = f'YoutubeComments_{i}.csv'\n",
    "    df.to_csv(csv_file, index=False, encoding='utf-8-sig')  # 한글 깨짐 방지\n",
    "\n",
    "    # 기존 CSV 파일과 병합\n",
    "    if os.path.exists(merged_csv_file):\n",
    "        df.to_csv(merged_csv_file, mode='a', index=False, header=False, encoding='utf-8-sig')\n",
    "    else:\n",
    "        df.to_csv(merged_csv_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # JSON 파일 삭제\n",
    "    os.remove(json_file)\n",
    "\n",
    "print(f\"모든 URL의 댓글이 {merged_csv_file} 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ef1da-3748-462f-a0d4-1a29e5b8fa3b",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c2cf0e-9f2d-4b3c-9c51-77fe62465be2",
   "metadata": {},
   "source": [
    "# 1. 윤석열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0bd6ea-370d-4562-9328-13c178f2b9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 URL의 댓글이 yonhap_ysy_youtube_comments2.txt 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# '링크' 열에 유튜브 URL이 저장된 CSV 파일 경로\n",
    "input_csv_file = '윤석열_연합뉴스TV_유튜브목록.csv'\n",
    "output_text_file = 'yonhap_ysy_youtube_comments2.txt'\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df_urls = pd.read_csv(input_csv_file)\n",
    "urls = df_urls['링크'].dropna().tolist()\n",
    "\n",
    "# 댓글 저장 함수\n",
    "def process_url(i, url):\n",
    "    json_file = f'YoutubeComments_{i}.json'\n",
    "    os.system(f\"youtube-comment-downloader --url {url} --output {json_file}\")\n",
    "\n",
    "    comments = []\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            comment_data = json.loads(line)\n",
    "            comment = comment_data.get('text', '').strip()\n",
    "            comments.append(comment)\n",
    "\n",
    "    os.remove(json_file)\n",
    "    return comments\n",
    "\n",
    "# 텍스트 파일 초기화\n",
    "open(output_text_file, 'w').close()\n",
    "\n",
    "# 병렬 처리\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:  # 최대 5개의 스레드 사용\n",
    "    futures = [executor.submit(process_url, i, url) for i, url in enumerate(urls)]\n",
    "\n",
    "    with open(output_text_file, 'a', encoding='utf-8') as text_file:\n",
    "        for future in futures:\n",
    "            try:\n",
    "                comments = future.result()\n",
    "                for comment in comments:\n",
    "                    text_file.write(f\"{comment}\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"오류 발생: {e}\")\n",
    "\n",
    "print(f\"모든 URL의 댓글이 {output_text_file} 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37877080-4111-4e5f-a9b5-9df905f3a643",
   "metadata": {},
   "source": [
    "# 2. 이재명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f99cde97-5870-4f34-b5c0-c2a1773cc202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 URL의 댓글이 yonhap_ljm_youtube_comments.txt 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# '링크' 열에 유튜브 URL이 저장된 CSV 파일 경로\n",
    "input_csv_file = '이재명_연합뉴스TV_유튜브목록.csv'\n",
    "output_text_file = 'yonhap_ljm_youtube_comments.txt'\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df_urls = pd.read_csv(input_csv_file)\n",
    "urls = df_urls['링크'].dropna().tolist()\n",
    "\n",
    "# 댓글 저장 함수\n",
    "def process_url(i, url):\n",
    "    json_file = f'YoutubeComments_{i}.json'\n",
    "    os.system(f\"youtube-comment-downloader --url {url} --output {json_file}\")\n",
    "\n",
    "    comments = []\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            comment_data = json.loads(line)\n",
    "            comment = comment_data.get('text', '').strip()\n",
    "            comments.append(comment)\n",
    "\n",
    "    os.remove(json_file)\n",
    "    return comments\n",
    "\n",
    "# 텍스트 파일 초기화\n",
    "open(output_text_file, 'w').close()\n",
    "\n",
    "# 병렬 처리\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:  # 최대 5개의 스레드 사용\n",
    "    futures = [executor.submit(process_url, i, url) for i, url in enumerate(urls)]\n",
    "\n",
    "    with open(output_text_file, 'a', encoding='utf-8') as text_file:\n",
    "        for future in futures:\n",
    "            try:\n",
    "                comments = future.result()\n",
    "                for comment in comments:\n",
    "                    text_file.write(f\"{comment}\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"오류 발생: {e}\")\n",
    "\n",
    "print(f\"모든 URL의 댓글이 {output_text_file} 파일에 저장되었습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
