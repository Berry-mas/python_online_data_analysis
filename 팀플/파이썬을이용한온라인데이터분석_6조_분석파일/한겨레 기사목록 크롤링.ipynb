{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430ed9c8-a204-4b3f-84d1-56d983e54975",
   "metadata": {},
   "source": [
    "# 1. 윤석열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "562f8499-af14-45bd-a09b-eafbd2158a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 CSV 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Chrome 옵션 설정\n",
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option(\"detach\", True)\n",
    "chrome_options.add_argument(\"--disable-notifications\")  # 알림 비활성화\n",
    "chrome_options.add_argument(\"--start-maximized\")  # 브라우저 최대화\n",
    "chrome_options.add_argument(\"--disable-popup-blocking\")  # 팝업 차단 비활성화\n",
    "\n",
    "# ChromeDriver 경로 설정 및 Service 객체 생성\n",
    "s = Service(r\"C:\\Users\\junse\\2024-2\\python_onlinedata_analysis\\chromedriver-win64\\chromedriver.exe\")  # ChromeDriver 실행 파일 경로\n",
    "driver = webdriver.Chrome(service=s, options=chrome_options)  # WebDriver 객체 생성\n",
    "\n",
    "titles, links, dates = [], [], [] # 제목, 링크, 작성일자를 저장할 리스트 생성\n",
    "\n",
    "# 한겨레 사이트 접속\n",
    "for numb in range(1,21):\n",
    "    url_H = f\"https://search.hani.co.kr/search/newslist?searchword=%EC%9C%A4%EC%84%9D%EC%97%B4&startdate=20220215&enddate=20220308&page={numb}&sort=related\"\n",
    "    driver.get(url_H)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "    # 기사 데이터 크롤링\n",
    "    time.sleep(3)\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, \"lxml\")  # BeautifulSoup으로 HTML 파싱\n",
    "\n",
    "    articles = soup.find_all(\"article\")\n",
    "    for article in articles:\n",
    "        try:\n",
    "            # 제목과 링크\n",
    "            title_tag = article.find(\"strong\")\n",
    "            link_tag = article.find(\"a\", href=True)\n",
    "            if title_tag and link_tag:\n",
    "                titles.append(title_tag.get_text(strip=True))\n",
    "                links.append(link_tag[\"href\"])\n",
    "            else:\n",
    "                titles.append(\"제목 없음\")\n",
    "                links.append(\"링크 없음\")\n",
    "        except Exception as e:\n",
    "            print(f\"기사 제목/링크 데이터 추출 오류: {e}\")\n",
    "    \n",
    "        try:\n",
    "            # 날짜 추출\n",
    "            date_tag = article.find(\"span\", class_=\"article-date\")\n",
    "            if date_tag:\n",
    "                dates.append(date_tag.get_text(strip=True))\n",
    "            else:\n",
    "                dates.append(\"날짜 없음\")\n",
    "        except Exception as e:\n",
    "            print(f\"날짜 데이터 추출 오류: {e}\")\n",
    "#--------------------------------------------------------------------------------------------------------------\n",
    "# 데이터 저장\n",
    "try:\n",
    "    df = pd.DataFrame({\"제목\": titles, \"링크\": links, \"작성일자\": dates})\n",
    "    df.to_csv(\"윤석열_한겨레_기사목록200.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"데이터가 CSV 파일로 저장되었습니다.\")\n",
    "except Exception as e:\n",
    "    print(\"CSV 저장 중 오류 발생:\", e)\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac73701c-2306-490a-a235-d237c5b0eb99",
   "metadata": {},
   "source": [
    "# 2. 이재명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2108f234-250e-4758-9449-0d72d2a9c39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 CSV 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "## 이거 반복\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Chrome 옵션 설정\n",
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option(\"detach\", True)\n",
    "chrome_options.add_argument(\"--disable-notifications\")  # 알림 비활성화\n",
    "chrome_options.add_argument(\"--start-maximized\")  # 브라우저 최대화\n",
    "chrome_options.add_argument(\"--disable-popup-blocking\")  # 팝업 차단 비활성화\n",
    "\n",
    "# ChromeDriver 경로 설정 및 Service 객체 생성\n",
    "s = Service(r\"C:\\Users\\junse\\2024-2\\python_onlinedata_analysis\\chromedriver-win64\\chromedriver.exe\")  # ChromeDriver 실행 파일 경로\n",
    "driver = webdriver.Chrome(service=s, options=chrome_options)  # WebDriver 객체 생성\n",
    "titles, links, dates = [], [], [] # 제목, 링크, 작성일자를 저장할 리스트 생성\n",
    "\n",
    "# 한겨레 사이트 접속\n",
    "for numb in range(1,21):\n",
    "    url_H = f\"https://search.hani.co.kr/search/newslist?searchword=%EC%9D%B4%EC%9E%AC%EB%AA%85&startdate=20220215&enddate=20220308&page={numb}&sort=related\"\n",
    "    driver.get(url_H)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "    # 기사 데이터 크롤링\n",
    "    time.sleep(3)\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, \"lxml\")  # BeautifulSoup으로 HTML 파싱\n",
    "\n",
    "    articles = soup.find_all(\"article\")\n",
    "    for article in articles:\n",
    "        try:\n",
    "            # 제목과 링크\n",
    "            title_tag = article.find(\"strong\")\n",
    "            link_tag = article.find(\"a\", href=True)\n",
    "            if title_tag and link_tag:\n",
    "                titles.append(title_tag.get_text(strip=True))\n",
    "                links.append(link_tag[\"href\"])\n",
    "            else:\n",
    "                titles.append(\"제목 없음\")\n",
    "                links.append(\"링크 없음\")\n",
    "        except Exception as e:\n",
    "            print(f\"기사 제목/링크 데이터 추출 오류: {e}\")\n",
    "    \n",
    "        try:\n",
    "            # 날짜 추출\n",
    "            date_tag = article.find(\"span\", class_=\"article-date\")\n",
    "            if date_tag:\n",
    "                dates.append(date_tag.get_text(strip=True))\n",
    "            else:\n",
    "                dates.append(\"날짜 없음\")\n",
    "        except Exception as e:\n",
    "            print(f\"날짜 데이터 추출 오류: {e}\")\n",
    "#--------------------------------------------------------------------------------------------------------------\n",
    "# 데이터 저장\n",
    "try:\n",
    "    df = pd.DataFrame({\"제목\": titles, \"링크\": links, \"작성일자\": dates})\n",
    "    df.to_csv(\"이재명_한겨레_기사목록200.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"데이터가 CSV 파일로 저장되었습니다.\")\n",
    "except Exception as e:\n",
    "    print(\"CSV 저장 중 오류 발생:\", e)\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
